{"cells":[{"cell_type":"markdown","metadata":{"id":"KxDU6uXEi7T-"},"source":["# preprocess wikipedia corpus"],"id":"KxDU6uXEi7T-"},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"BM5eSTNwOgLN","executionInfo":{"status":"ok","timestamp":1665804067182,"user_tz":-480,"elapsed":42,"user":{"displayName":"tim huang","userId":"03672479409652519123"}},"outputId":"0cba93cf-4535-452e-8c68-a1c18af8437c"},"id":"BM5eSTNwOgLN","execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Z1IASFZYOojr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665804098323,"user_tz":-480,"elapsed":25015,"user":{"displayName":"tim huang","userId":"03672479409652519123"}},"outputId":"1154558c-d717-42be-dc41-5d41fa19744b"},"id":"Z1IASFZYOojr","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"n89MoYXkkiwm"},"source":["## load word piece model for tokeniztion usage"],"id":"n89MoYXkkiwm"},{"cell_type":"code","execution_count":3,"metadata":{"id":"j_A2hVwYi5K4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665804113070,"user_tz":-480,"elapsed":10932,"user":{"displayName":"tim huang","userId":"03672479409652519123"}},"outputId":"59d5b9e2-3927-43de-f63b-2d7c42811c5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 10.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 44.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"]}],"source":["!pip install transformers"],"id":"j_A2hVwYi5K4"},{"cell_type":"code","execution_count":4,"metadata":{"id":"TWI2lIEdi_4L","executionInfo":{"status":"ok","timestamp":1665804115720,"user_tz":-480,"elapsed":2674,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["from transformers import BertTokenizer, BertModel\n","import numpy as np"],"id":"TWI2lIEdi_4L"},{"cell_type":"markdown","metadata":{"id":"QtCcgG6QkrzH"},"source":["## load corpus"],"id":"QtCcgG6QkrzH"},{"cell_type":"code","execution_count":5,"metadata":{"id":"JQazVT9kkfu7","executionInfo":{"status":"ok","timestamp":1665804115724,"user_tz":-480,"elapsed":28,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class utils(object):\n","  def __init__(self,path=None):\n","    self.path=path\n","    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","  def preprocess_wiki(self, path):\n","    f = open(self.path)\n","    res = f.read().splitlines()\n","    f.close()\n","\n","    vocab=set()\n","    length=[]\n","    sentence_arr=[]\n","    for i in range(len(res)):\n","      text=res[i]\n","      tokenized_text = self.tokenizer.tokenize(text)\n","      # remove sentence which is too short, too long\n","      if 5<= len(tokenized_text)<=100:\n","        sentence_arr.append(tokenized_text)\n","        length.append(len(tokenized_text))\n","        vocab.update(tokenized_text)\n","\n","    v2i={v: i for i, v in enumerate(sorted(vocab), start=1)}\n","    v2i['<PAD>']=0\n","    v2i[\"<SEP>\"] = len(v2i) # <GO> as start of sequence ,<SEP> as end of sequence\n","    v2i[\"<GO>\"] = len(v2i) # the total number of tokens should include these special tokens: len(v2i)\n","\n","    i2v = {i: v for v, i in v2i.items()}  \n","    return sentence_arr, v2i, i2v, max(length)\n","\n","  def token_to_idx(self,sentence_arr, v2i):\n","    sentence_idx=[]\n","    for i in range(len(sentence_arr)):\n","      sentence_idx.append([v2i['<GO>']]+[v2i[item] for item in sentence_arr[i]]+[v2i['<SEP>']])\n","    return sentence_idx\n","\n","  # add a pad_zero function to align the sentences of various length\n","  def pad_zero(self, seqs, max_len):\n","      PAD_ID = 0\n","      padded = np.full((len(seqs), max_len), fill_value=PAD_ID, dtype=np.int32)\n","      for i, seq in enumerate(seqs):\n","          padded[i, :len(seq)] = seq\n","      return padded\n","\n","  def get_idx_sentence(self):\n","    sentence_arr, v2i, i2v, max_len= self.preprocess_wiki(self.path) #input is part of wiki data, for demo usage\n","    sentence_idx = self.token_to_idx(sentence_arr, v2i)\n","    # define idx for padding\n","    PAD_ID= v2i['<PAD>']\n","    # there is <GO> and <SEP> at start and ending of sentence, so the full length should be 100+2=102\n","    sentence_idx_padded = self.pad_zero(sentence_idx,max_len+2)\n","\n","    return sentence_idx_padded.tolist(), v2i\n","\n"],"id":"JQazVT9kkfu7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ziYud6Twn0tN"},"outputs":[],"source":[],"id":"ziYud6Twn0tN"},{"cell_type":"markdown","metadata":{"id":"9120f617"},"source":["# define the module and gpt class"],"id":"9120f617"},{"cell_type":"code","execution_count":6,"metadata":{"id":"c5c4953e","executionInfo":{"status":"ok","timestamp":1665804119847,"user_tz":-480,"elapsed":16,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["from torch import Tensor\n","import torch.nn.functional as f"],"id":"c5c4953e"},{"cell_type":"code","execution_count":7,"metadata":{"id":"07ca3d26","executionInfo":{"status":"ok","timestamp":1665804119850,"user_tz":-480,"elapsed":14,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","class AttentionHead(nn.Module):\n","    def __init__(self, dim_in: int, dim_k: int, dim_v: int):\n","        super().__init__()\n","        self.q = nn.Linear(dim_in, dim_k)\n","        self.k = nn.Linear(dim_in, dim_k)\n","        self.v = nn.Linear(dim_in, dim_v)\n","        #self.embedding=nn.Embedding() ##\n","\n","    def forward(self, query: Tensor, key: Tensor, value: Tensor, mask: Tensor) -> Tensor:  ## 传入mask \n","        query= self.q(query)\n","        key= self.k(key)\n","        value=self.v(value)\n","\n","        temp = query.bmm(key.transpose(1, 2))\n","        scale = query.size(-1) ** 0.5\n","\n","        score=temp/scale\n","        score=score+mask\n","\n","        softmax = f.softmax(score, dim=-1)\n","        return softmax.bmm(value)"],"id":"07ca3d26"},{"cell_type":"code","execution_count":8,"metadata":{"id":"7ec0dc65","executionInfo":{"status":"ok","timestamp":1665804122568,"user_tz":-480,"elapsed":9,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, num_heads: int, dim_in: int, dim_k: int, dim_v: int):\n","        super().__init__()\n","        self.heads = nn.ModuleList(\n","            [AttentionHead(dim_in, dim_k, dim_v) for _ in range(num_heads)]\n","        )\n","        self.linear = nn.Linear(num_heads * dim_v, dim_in)\n","\n","    def forward(self, query: Tensor, key: Tensor, value: Tensor, mask) -> Tensor: ## 传入mask\n","        return self.linear(\n","            torch.cat([h(query, key, value,mask) for h in self.heads], dim=-1)\n","        )"],"id":"7ec0dc65"},{"cell_type":"code","execution_count":10,"metadata":{"id":"58cd2c04","executionInfo":{"status":"ok","timestamp":1665804129267,"user_tz":-480,"elapsed":765,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["def position_encoding(\n","    seq_len: int, dim_model: int, device: torch.device = torch.device(\"cpu\"),\n",") -> Tensor:\n","    pos = torch.arange(seq_len, dtype=torch.float, device=device).reshape(1, -1, 1)\n","    dim = torch.arange(dim_model, dtype=torch.float, device=device).reshape(1, 1, -1)\n","    phase = pos / 1e4 ** (dim // dim_model)\n","\n","    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))"],"id":"58cd2c04"},{"cell_type":"code","execution_count":11,"metadata":{"id":"f70a440b","executionInfo":{"status":"ok","timestamp":1665804131524,"user_tz":-480,"elapsed":10,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["def feed_forward(dim_input: int = 512, dim_feedforward: int = 2048) -> nn.Module:\n","    return nn.Sequential(\n","        nn.Linear(dim_input, dim_feedforward),\n","        nn.ReLU(),\n","        nn.Linear(dim_feedforward, dim_input),\n","    )"],"id":"f70a440b"},{"cell_type":"code","execution_count":12,"metadata":{"id":"1c999324","executionInfo":{"status":"ok","timestamp":1665804132516,"user_tz":-480,"elapsed":11,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class Residual(nn.Module):\n","    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1): ##不是在这里传入mask\n","        super().__init__()\n","        self.sublayer = sublayer\n","        self.norm = nn.LayerNorm(dimension)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tensors0: Tensor, tensors1: Tensor, tensors2: Tensor, mask: Tensor) -> Tensor:\n","        # Assume that the \"value\" tensor is given last, so we can compute the\n","        # residual.  This matches the signature of 'MultiHeadAttention'.\n","        # self.mask=mask\n","        return self.norm(tensors0 + self.dropout(self.sublayer(tensors0, tensors1, tensors2,mask))) ## 传入mask"],"id":"1c999324"},{"cell_type":"code","execution_count":13,"metadata":{"id":"8473db38","executionInfo":{"status":"ok","timestamp":1665804134550,"user_tz":-480,"elapsed":416,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["## feed fowward network,Residual需要传入mask，这里不用，所以要分别开\n","class Residual_ffn(nn.Module):\n","    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1): ##不传入mask\n","        super().__init__()\n","        self.sublayer = sublayer\n","        self.norm = nn.LayerNorm(dimension)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tensors: Tensor) -> Tensor:\n","        # Assume that the \"value\" tensor is given last, so we can compute the\n","        # residual.  This matches the signature of 'MultiHeadAttention'.\n","        #self.mask=mask ##\n","        return self.norm(tensors + self.dropout(self.sublayer(tensors)))"],"id":"8473db38"},{"cell_type":"code","execution_count":14,"metadata":{"id":"b13c689b","executionInfo":{"status":"ok","timestamp":1665804135706,"user_tz":-480,"elapsed":8,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(\n","        self, \n","        dim_model: int = 512, \n","        num_heads: int = 6, \n","        dim_feedforward: int = 2048, \n","        dropout: float = 0.1, \n","    ):\n","        super().__init__()\n","        dim_k = dim_v = dim_model // num_heads\n","        self.attention = Residual(\n","            MultiHeadAttention(num_heads, dim_model, dim_k, dim_v), ## 传入mask\n","            dimension=dim_model,\n","            dropout=dropout, \n","        )\n","        self.feed_forward = Residual_ffn(\n","            feed_forward(dim_model, dim_feedforward),\n","            dimension=dim_model,\n","            dropout=dropout,\n","        )\n","\n","    def forward(self, src: Tensor,mask: Tensor) -> Tensor: ##传入mask\n","        src = self.attention(src, src, src,mask) ###传入mask\n","        #return src \n","        return self.feed_forward(src)"],"id":"b13c689b"},{"cell_type":"code","execution_count":15,"metadata":{"id":"cdb862e9","executionInfo":{"status":"ok","timestamp":1665804142635,"user_tz":-480,"elapsed":465,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class TransformerEncoder(nn.Module):\n","    def __init__(\n","        self, \n","        num_layers: int = 6,\n","        dim_model: int = 512, \n","        num_heads: int = 8, \n","        dim_feedforward: int = 2048, \n","        dropout: float = 0.1,\n","        device: str = 'cpu' \n","    ):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            TransformerEncoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n","            for _ in range(num_layers)\n","        ])\n","        self.device= device\n","\n","    def forward(self, src: Tensor, mask: Tensor) -> Tensor: ##可以传入mask\n","        seq_len, dimension = src.size(1), src.size(2)\n","        pos=position_encoding(seq_len,dimension, torch.device(self.device) ) #\n","        #pos=pos.cuda(0) # load data to gpu\n","        src += pos\n","        for layer in self.layers:\n","            src = layer(src,mask)  ##传入mask\n","\n","        return src"],"id":"cdb862e9"},{"cell_type":"code","execution_count":16,"metadata":{"id":"11cf4eb7","executionInfo":{"status":"ok","timestamp":1665804144340,"user_tz":-480,"elapsed":12,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["# start a trial of gpt model testing\n","class GPT(nn.Module):\n","    def __init__(\n","        self, \n","        num_encoder_layers: int = 4,\n","        dim_model: int = 512, \n","        num_heads: int = 8, \n","        dim_feedforward: int = 2048//2, \n","        dropout: float = 0.1, \n","        activation: nn.Module = nn.ReLU(),\n","        n_vocab: int=4,\n","        device: str = 'cpu'\n","    ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(n_vocab, dim_model)\n","        \n","        self.encoder = TransformerEncoder(\n","            num_layers=num_encoder_layers,\n","            dim_model=dim_model,\n","            num_heads=num_heads,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            device= device\n","        )\n","\n","        self.out = nn.Linear(dim_model, n_vocab)\n","\n","\n","\n","    def forward(self, src: Tensor, mask: Tensor) -> Tensor: ##传入mask\n","        emb=self.embedding(src)\n","        enc=self.encoder(emb,mask) ##传入mask\n","        out=self.out(enc)\n","        \n","        return out ##no need softmax, nn.cross_entropy take care of it"],"id":"11cf4eb7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"11785966"},"outputs":[],"source":[],"id":"11785966"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1a7b865"},"outputs":[],"source":[],"id":"e1a7b865"},{"cell_type":"markdown","metadata":{"id":"02903460"},"source":["# load data"],"id":"02903460"},{"cell_type":"code","execution_count":16,"metadata":{"id":"919aebd4","executionInfo":{"status":"ok","timestamp":1665804151575,"user_tz":-480,"elapsed":367,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":[],"id":"919aebd4"},{"cell_type":"markdown","metadata":{"id":"9caecf34"},"source":["# train model"],"id":"9caecf34"},{"cell_type":"code","execution_count":17,"metadata":{"id":"bf2b36ea","executionInfo":{"status":"ok","timestamp":1665804153085,"user_tz":-480,"elapsed":9,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["# Generates a square matrix where the each row allows one word more to be seen\n","\n","def generate_masks(src):\n","    seq_len= src.size(1)\n","\n","    pad_int= [int(seq_len-i) for i in src.count_nonzero(dim=1)]\n","\n","    mask = torch.tril(torch.ones(seq_len, seq_len) == 1) # Lower triangular matrix\n","    mask = mask.float()\n","    mask = mask.masked_fill(mask == 0, -1e9) # Convert zeros to -1e9\n","    mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n","\n","    mask_arr=[]\n","    for i in pad_int:\n","      mask[:,-(i):]= -1e9\n","      mask_arr.append(mask)\n","\n","    masks=torch.cat(tuple(mask_arr),dim=0)\n","    masks=masks.reshape(src.size(0),seq_len,seq_len)\n","    \n","    return masks"],"id":"bf2b36ea"},{"cell_type":"code","execution_count":18,"metadata":{"id":"9f8d45f2","executionInfo":{"status":"ok","timestamp":1665804155444,"user_tz":-480,"elapsed":12,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["import time\n","\n","######\n","def loss_masked(output, src, loss_fn):\n","    nonpad_int=src.count_nonzero(dim=1)\n","    # discard pad elements\n","    res=[]\n","    for k,item in enumerate(nonpad_int):\n","        res.append(src[k][:int(item)])\n","\n","    loss_res=0\n","    for i in range(src.size(0)):\n","        loss_res+=loss_fn(output[i], src[i])\n","\n","    return loss_res/src.size(0)\n","######\n","\n","def train(model, data, batch_size):\n","    torch.manual_seed(0)\n","    model.to(device)\n","\n","    # define loss function (criterion) and optimizer\n","    loss_fn = nn.CrossEntropyLoss().to(device)  ## this is for classification\n","    opt = torch.optim.SGD(model.parameters(), 1e-4)\n","\n","\n","    n=len(data)// batch_size\n","\n","    # prepare for next word prediction\n","    t0=time.time()\n","\n","    for i in range(n):\n","        src=data[batch_size*i:batch_size*(i+1)]\n","        src=torch.tensor(src).long()\n","\n","        _seq=src[:,:-1]\n","        seq_=src[:,1:]\n","        masks=generate_masks(_seq)\n","\n","        \n","        #put to gpu\n","        _seq=_seq.to(device)\n","        seq_=seq_.to(device)\n","        masks=masks.to(device)\n","\n","        # Forward pass\n","        outputs = model(_seq,masks)\n","        loss=loss_masked(outputs,seq_, loss_fn) # next word prediction\n","\n","        # the part of padding loss should be removed before backprop\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n","        print(loss.detach().item())\n","    print(time.time()-t0)\n","        \n","        #if i%10000==0: np.savetxt('./torch_save_model/gpt_loss_%d.csv'%(i), np.array([loss.detach().item()]))\n","\n","    # save model parameters after finish training model\n","    torch.save(model, \"./model.pkl\")"],"id":"9f8d45f2"},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167},"id":"JfdRCQmthltG","executionInfo":{"status":"error","timestamp":1665804159941,"user_tz":-480,"elapsed":414,"user":{"displayName":"tim huang","userId":"03672479409652519123"}},"outputId":"5b72e74c-2170-453e-d0e3-67f69c65a8ac"},"id":"JfdRCQmthltG","execution_count":19,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-305df3368e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"90873858","colab":{"base_uri":"https://localhost:8080/","height":524,"referenced_widgets":["28db065772864471ae7dc0d92781992f","b26386a85f174b5f8996a078d1603634","faa79a4ce26c4570ab3bfb78718934bd","fd7a6fa41e8e46c58e52714d88737b1a","4486062b8c204c92accab7abfb87988d","a272e72a4bbe40f0a131b73e3e7b8970","f1eec1e69af645faa23c796df1932a04","b9e5b43cfe6a4ca3a017576684fc56de","fbd24a21965e4da3bb7dfceccdf43163","8f4e4ae68fbb4664b2189dd3cf9c7624","ca4b2552ced947b2ac724d28e537bc48","c66de37bc3d04d80a1977c49ef1792fe","7c752468278e4738b6be0a0273a80c52","47de97d6db0748cbaaaac35d68ceaaa0","f0283ed30db44e058799eb41df6adc16","0f5d8c4156dc460d80ff5b6dd765948d","86f4a5f39e9842c18e61a165f28472cd","fc5fcd8ca5034bcaa2119f5f2c3de381","4dbf71ab8bf84576968d55b836d8cb65","108d3b00ff83492da9a2097e43f15d99","51e0d60222ba4e7a9debec798d75a885","d0da72237b064256970516af459f8cee","c16fe8b7a3ee4dea827b51dd43b7d70b","b201cfde6ac4424492d4d33fc2887582","671dff2a29c1426985eefba88998f516","76e48b82ff75441e882d381e9321d65a","c45c500756b94b72aacc428ae10917dd","08eb4faca96147d8959cd6cc0f509264","79e897c653ca40e2bd3d0e5832fa551d","7440e30ae7d04743bbd1d33f25ab5557","4dba6a3457414981974d07ffbc4dcd9b","fd9d7556ab7542d1a466871dee4839c5","3462d0c1c9fb4679be7f4e259e6bf779"]},"outputId":"23b01209-161c-4f0e-ae95-83579ec50d72"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28db065772864471ae7dc0d92781992f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c66de37bc3d04d80a1977c49ef1792fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16fe8b7a3ee4dea827b51dd43b7d70b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  \n"]},{"output_type":"stream","name":"stdout","text":["9.704425811767578\n","9.671913146972656\n","9.671069145202637\n","9.373780250549316\n","9.636103630065918\n","9.584640502929688\n","9.521275520324707\n","9.513204574584961\n","9.534192085266113\n","9.463265419006348\n","9.231632232666016\n","9.511894226074219\n","9.383188247680664\n","9.34734058380127\n","9.346139907836914\n","9.258397102355957\n","9.286152839660645\n","9.271854400634766\n","9.25654125213623\n","9.264501571655273\n"]}],"source":["# the entry to start training the model, with data, with specified parameter\n","if __name__ == '__main__':\n","    # load cpu or gpu name\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","    # model parameter\n","    MODEL_DIM = 256\n","    N_LAYER = 4\n","    N_HEAD = 8\n","    # training argument\n","    batch_size = 128\n","    # load data\n","    ut = utils(path='/content/drive/MyDrive/goodnlp-github-data/single_gpu_pytorch_gpt/file00')\n","    d, v2i=ut.get_idx_sentence()\n","    n_vocab= len(v2i)\n","    m= GPT(num_encoder_layers= N_LAYER,dim_model= MODEL_DIM, num_heads= N_HEAD, n_vocab=n_vocab, device=device)\n","    # start training\n","    train(m, d, batch_size)"],"id":"90873858"}],"metadata":{"colab":{"provenance":[{"file_id":"1o7hz4unyEbrEa215fqKweoYtGaWedgSk","timestamp":1665765566278}],"collapsed_sections":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"28db065772864471ae7dc0d92781992f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b26386a85f174b5f8996a078d1603634","IPY_MODEL_faa79a4ce26c4570ab3bfb78718934bd","IPY_MODEL_fd7a6fa41e8e46c58e52714d88737b1a"],"layout":"IPY_MODEL_4486062b8c204c92accab7abfb87988d"}},"b26386a85f174b5f8996a078d1603634":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a272e72a4bbe40f0a131b73e3e7b8970","placeholder":"​","style":"IPY_MODEL_f1eec1e69af645faa23c796df1932a04","value":"Downloading: 100%"}},"faa79a4ce26c4570ab3bfb78718934bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9e5b43cfe6a4ca3a017576684fc56de","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbd24a21965e4da3bb7dfceccdf43163","value":231508}},"fd7a6fa41e8e46c58e52714d88737b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f4e4ae68fbb4664b2189dd3cf9c7624","placeholder":"​","style":"IPY_MODEL_ca4b2552ced947b2ac724d28e537bc48","value":" 232k/232k [00:00&lt;00:00, 824kB/s]"}},"4486062b8c204c92accab7abfb87988d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a272e72a4bbe40f0a131b73e3e7b8970":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1eec1e69af645faa23c796df1932a04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9e5b43cfe6a4ca3a017576684fc56de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbd24a21965e4da3bb7dfceccdf43163":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f4e4ae68fbb4664b2189dd3cf9c7624":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca4b2552ced947b2ac724d28e537bc48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c66de37bc3d04d80a1977c49ef1792fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c752468278e4738b6be0a0273a80c52","IPY_MODEL_47de97d6db0748cbaaaac35d68ceaaa0","IPY_MODEL_f0283ed30db44e058799eb41df6adc16"],"layout":"IPY_MODEL_0f5d8c4156dc460d80ff5b6dd765948d"}},"7c752468278e4738b6be0a0273a80c52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86f4a5f39e9842c18e61a165f28472cd","placeholder":"​","style":"IPY_MODEL_fc5fcd8ca5034bcaa2119f5f2c3de381","value":"Downloading: 100%"}},"47de97d6db0748cbaaaac35d68ceaaa0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dbf71ab8bf84576968d55b836d8cb65","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_108d3b00ff83492da9a2097e43f15d99","value":28}},"f0283ed30db44e058799eb41df6adc16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51e0d60222ba4e7a9debec798d75a885","placeholder":"​","style":"IPY_MODEL_d0da72237b064256970516af459f8cee","value":" 28.0/28.0 [00:00&lt;00:00, 562B/s]"}},"0f5d8c4156dc460d80ff5b6dd765948d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86f4a5f39e9842c18e61a165f28472cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc5fcd8ca5034bcaa2119f5f2c3de381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dbf71ab8bf84576968d55b836d8cb65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"108d3b00ff83492da9a2097e43f15d99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51e0d60222ba4e7a9debec798d75a885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0da72237b064256970516af459f8cee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c16fe8b7a3ee4dea827b51dd43b7d70b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b201cfde6ac4424492d4d33fc2887582","IPY_MODEL_671dff2a29c1426985eefba88998f516","IPY_MODEL_76e48b82ff75441e882d381e9321d65a"],"layout":"IPY_MODEL_c45c500756b94b72aacc428ae10917dd"}},"b201cfde6ac4424492d4d33fc2887582":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08eb4faca96147d8959cd6cc0f509264","placeholder":"​","style":"IPY_MODEL_79e897c653ca40e2bd3d0e5832fa551d","value":"Downloading: 100%"}},"671dff2a29c1426985eefba88998f516":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7440e30ae7d04743bbd1d33f25ab5557","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4dba6a3457414981974d07ffbc4dcd9b","value":570}},"76e48b82ff75441e882d381e9321d65a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd9d7556ab7542d1a466871dee4839c5","placeholder":"​","style":"IPY_MODEL_3462d0c1c9fb4679be7f4e259e6bf779","value":" 570/570 [00:00&lt;00:00, 10.2kB/s]"}},"c45c500756b94b72aacc428ae10917dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08eb4faca96147d8959cd6cc0f509264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79e897c653ca40e2bd3d0e5832fa551d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7440e30ae7d04743bbd1d33f25ab5557":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dba6a3457414981974d07ffbc4dcd9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd9d7556ab7542d1a466871dee4839c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3462d0c1c9fb4679be7f4e259e6bf779":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}