{"cells":[{"cell_type":"markdown","metadata":{"id":"KxDU6uXEi7T-"},"source":["# preprocess wikipedia corpus"],"id":"KxDU6uXEi7T-"},{"cell_type":"code","source":[],"metadata":{"id":"BM5eSTNwOgLN","executionInfo":{"status":"ok","timestamp":1665810891774,"user_tz":-480,"elapsed":477,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"id":"BM5eSTNwOgLN","execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n89MoYXkkiwm"},"source":["## load word piece model for tokeniztion usage"],"id":"n89MoYXkkiwm"},{"cell_type":"code","execution_count":20,"metadata":{"id":"j_A2hVwYi5K4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665810896469,"user_tz":-480,"elapsed":4270,"user":{"displayName":"tim huang","userId":"03672479409652519123"}},"outputId":"8950935c-6b74-4630-a918-494ed4f8faf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"]}],"source":["!pip install transformers"],"id":"j_A2hVwYi5K4"},{"cell_type":"code","execution_count":21,"metadata":{"id":"TWI2lIEdi_4L","executionInfo":{"status":"ok","timestamp":1665810896474,"user_tz":-480,"elapsed":120,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["from transformers import BertTokenizer, BertModel\n","import numpy as np"],"id":"TWI2lIEdi_4L"},{"cell_type":"markdown","metadata":{"id":"QtCcgG6QkrzH"},"source":["## load corpus"],"id":"QtCcgG6QkrzH"},{"cell_type":"code","execution_count":22,"metadata":{"id":"JQazVT9kkfu7","executionInfo":{"status":"ok","timestamp":1665810896479,"user_tz":-480,"elapsed":121,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class utils(object):\n","  def __init__(self,path=None):\n","    self.path=path\n","    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","  def preprocess_wiki(self, path):\n","    f = open(self.path)\n","    res = f.read().splitlines()\n","    f.close()\n","\n","    vocab=set()\n","    length=[]\n","    sentence_arr=[]\n","    for i in range(len(res)):\n","      text=res[i]\n","      tokenized_text = self.tokenizer.tokenize(text)\n","      # remove sentence which is too short, too long\n","      if 5<= len(tokenized_text)<=100:\n","        sentence_arr.append(tokenized_text)\n","        length.append(len(tokenized_text))\n","        vocab.update(tokenized_text)\n","\n","    v2i={v: i for i, v in enumerate(sorted(vocab), start=1)}\n","    v2i['<PAD>']=0\n","    v2i[\"<SEP>\"] = len(v2i) # <GO> as start of sequence ,<SEP> as end of sequence\n","    v2i[\"<GO>\"] = len(v2i) # the total number of tokens should include these special tokens: len(v2i)\n","\n","    i2v = {i: v for v, i in v2i.items()}  \n","    return sentence_arr, v2i, i2v, max(length)\n","\n","  def token_to_idx(self,sentence_arr, v2i):\n","    sentence_idx=[]\n","    for i in range(len(sentence_arr)):\n","      sentence_idx.append([v2i['<GO>']]+[v2i[item] for item in sentence_arr[i]]+[v2i['<SEP>']])\n","    return sentence_idx\n","\n","  # add a pad_zero function to align the sentences of various length\n","  def pad_zero(self, seqs, max_len):\n","      PAD_ID = 0\n","      padded = np.full((len(seqs), max_len), fill_value=PAD_ID, dtype=np.int32)\n","      for i, seq in enumerate(seqs):\n","          padded[i, :len(seq)] = seq\n","      return padded\n","\n","  def get_idx_sentence(self):\n","    sentence_arr, v2i, i2v, max_len= self.preprocess_wiki(self.path) #input is part of wiki data, for demo usage\n","    sentence_idx = self.token_to_idx(sentence_arr, v2i)\n","    # define idx for padding\n","    PAD_ID= v2i['<PAD>']\n","    # there is <GO> and <SEP> at start and ending of sentence, so the full length should be 100+2=102\n","    sentence_idx_padded = self.pad_zero(sentence_idx,max_len+2)\n","\n","    return sentence_idx_padded.tolist(), v2i\n","\n"],"id":"JQazVT9kkfu7"},{"cell_type":"code","execution_count":22,"metadata":{"id":"ziYud6Twn0tN","executionInfo":{"status":"ok","timestamp":1665810896496,"user_tz":-480,"elapsed":136,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":[],"id":"ziYud6Twn0tN"},{"cell_type":"markdown","metadata":{"id":"9120f617"},"source":["# define the module and gpt class"],"id":"9120f617"},{"cell_type":"code","execution_count":23,"metadata":{"id":"c5c4953e","executionInfo":{"status":"ok","timestamp":1665810896502,"user_tz":-480,"elapsed":138,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["from torch import Tensor\n","import torch.nn.functional as f"],"id":"c5c4953e"},{"cell_type":"code","execution_count":24,"metadata":{"id":"07ca3d26","executionInfo":{"status":"ok","timestamp":1665810896505,"user_tz":-480,"elapsed":138,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","class AttentionHead(nn.Module):\n","    def __init__(self, dim_in: int, dim_k: int, dim_v: int):\n","        super().__init__()\n","        self.q = nn.Linear(dim_in, dim_k)\n","        self.k = nn.Linear(dim_in, dim_k)\n","        self.v = nn.Linear(dim_in, dim_v)\n","        #self.embedding=nn.Embedding() ##\n","\n","    def forward(self, query: Tensor, key: Tensor, value: Tensor, mask: Tensor) -> Tensor:  ## 传入mask \n","        query= self.q(query)\n","        key= self.k(key)\n","        value=self.v(value)\n","\n","        temp = query.bmm(key.transpose(1, 2))\n","        scale = query.size(-1) ** 0.5\n","\n","        score=temp/scale\n","        score=score+mask\n","\n","        softmax = f.softmax(score, dim=-1)\n","        return softmax.bmm(value)"],"id":"07ca3d26"},{"cell_type":"code","execution_count":25,"metadata":{"id":"7ec0dc65","executionInfo":{"status":"ok","timestamp":1665810896509,"user_tz":-480,"elapsed":140,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, num_heads: int, dim_in: int, dim_k: int, dim_v: int):\n","        super().__init__()\n","        self.heads = nn.ModuleList(\n","            [AttentionHead(dim_in, dim_k, dim_v) for _ in range(num_heads)]\n","        )\n","        self.linear = nn.Linear(num_heads * dim_v, dim_in)\n","\n","    def forward(self, query: Tensor, key: Tensor, value: Tensor, mask) -> Tensor: ## 传入mask\n","        return self.linear(\n","            torch.cat([h(query, key, value,mask) for h in self.heads], dim=-1)\n","        )"],"id":"7ec0dc65"},{"cell_type":"code","execution_count":26,"metadata":{"id":"58cd2c04","executionInfo":{"status":"ok","timestamp":1665810896515,"user_tz":-480,"elapsed":144,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["def position_encoding(\n","    seq_len: int, dim_model: int, device: torch.device = torch.device(\"cpu\"),\n",") -> Tensor:\n","    pos = torch.arange(seq_len, dtype=torch.float, device=device).reshape(1, -1, 1)\n","    dim = torch.arange(dim_model, dtype=torch.float, device=device).reshape(1, 1, -1)\n","    phase = pos / 1e4 ** (dim // dim_model)\n","\n","    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))"],"id":"58cd2c04"},{"cell_type":"code","execution_count":27,"metadata":{"id":"f70a440b","executionInfo":{"status":"ok","timestamp":1665810896518,"user_tz":-480,"elapsed":144,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["def feed_forward(dim_input: int = 512, dim_feedforward: int = 2048) -> nn.Module:\n","    return nn.Sequential(\n","        nn.Linear(dim_input, dim_feedforward),\n","        nn.ReLU(),\n","        nn.Linear(dim_feedforward, dim_input),\n","    )"],"id":"f70a440b"},{"cell_type":"code","execution_count":28,"metadata":{"id":"1c999324","executionInfo":{"status":"ok","timestamp":1665810896521,"user_tz":-480,"elapsed":144,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class Residual(nn.Module):\n","    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1): ##不是在这里传入mask\n","        super().__init__()\n","        self.sublayer = sublayer\n","        self.norm = nn.LayerNorm(dimension)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tensors0: Tensor, tensors1: Tensor, tensors2: Tensor, mask: Tensor) -> Tensor:\n","        # Assume that the \"value\" tensor is given last, so we can compute the\n","        # residual.  This matches the signature of 'MultiHeadAttention'.\n","        # self.mask=mask\n","        return self.norm(tensors0 + self.dropout(self.sublayer(tensors0, tensors1, tensors2,mask))) ## 传入mask"],"id":"1c999324"},{"cell_type":"code","execution_count":29,"metadata":{"id":"8473db38","executionInfo":{"status":"ok","timestamp":1665810896526,"user_tz":-480,"elapsed":147,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["## feed fowward network,Residual需要传入mask，这里不用，所以要分别开\n","class Residual_ffn(nn.Module):\n","    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1): ##不传入mask\n","        super().__init__()\n","        self.sublayer = sublayer\n","        self.norm = nn.LayerNorm(dimension)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tensors: Tensor) -> Tensor:\n","        # Assume that the \"value\" tensor is given last, so we can compute the\n","        # residual.  This matches the signature of 'MultiHeadAttention'.\n","        #self.mask=mask ##\n","        return self.norm(tensors + self.dropout(self.sublayer(tensors)))"],"id":"8473db38"},{"cell_type":"code","execution_count":30,"metadata":{"id":"b13c689b","executionInfo":{"status":"ok","timestamp":1665810896530,"user_tz":-480,"elapsed":149,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(\n","        self, \n","        dim_model: int = 512, \n","        num_heads: int = 6, \n","        dim_feedforward: int = 2048, \n","        dropout: float = 0.1, \n","    ):\n","        super().__init__()\n","        dim_k = dim_v = dim_model // num_heads\n","        self.attention = Residual(\n","            MultiHeadAttention(num_heads, dim_model, dim_k, dim_v), ## 传入mask\n","            dimension=dim_model,\n","            dropout=dropout, \n","        )\n","        self.feed_forward = Residual_ffn(\n","            feed_forward(dim_model, dim_feedforward),\n","            dimension=dim_model,\n","            dropout=dropout,\n","        )\n","\n","    def forward(self, src: Tensor,mask: Tensor) -> Tensor: ##传入mask\n","        src = self.attention(src, src, src,mask) ###传入mask\n","        #return src \n","        return self.feed_forward(src)"],"id":"b13c689b"},{"cell_type":"code","execution_count":31,"metadata":{"id":"cdb862e9","executionInfo":{"status":"ok","timestamp":1665810896534,"user_tz":-480,"elapsed":150,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["class TransformerEncoder(nn.Module):\n","    def __init__(\n","        self, \n","        num_layers: int = 6,\n","        dim_model: int = 512, \n","        num_heads: int = 8, \n","        dim_feedforward: int = 2048, \n","        dropout: float = 0.1,\n","        device: str = 'cpu' \n","    ):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            TransformerEncoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n","            for _ in range(num_layers)\n","        ])\n","        self.device= device\n","\n","    def forward(self, src: Tensor, mask: Tensor) -> Tensor: ##可以传入mask\n","        seq_len, dimension = src.size(1), src.size(2)\n","        pos=position_encoding(seq_len,dimension, torch.device(self.device) ) #\n","        #pos=pos.cuda(0) # load data to gpu\n","        src += pos\n","        for layer in self.layers:\n","            src = layer(src,mask)  ##传入mask\n","\n","        return src"],"id":"cdb862e9"},{"cell_type":"code","execution_count":32,"metadata":{"id":"11cf4eb7","executionInfo":{"status":"ok","timestamp":1665810896537,"user_tz":-480,"elapsed":151,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["# start a trial of gpt model testing\n","class GPT(nn.Module):\n","    def __init__(\n","        self, \n","        num_encoder_layers: int = 4,\n","        dim_model: int = 512, \n","        num_heads: int = 8, \n","        dim_feedforward: int = 2048//2, \n","        dropout: float = 0.1, \n","        activation: nn.Module = nn.ReLU(),\n","        n_vocab: int=4,\n","        device: str = 'cpu'\n","    ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(n_vocab, dim_model)\n","        \n","        self.encoder = TransformerEncoder(\n","            num_layers=num_encoder_layers,\n","            dim_model=dim_model,\n","            num_heads=num_heads,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            device= device\n","        )\n","\n","        self.out = nn.Linear(dim_model, n_vocab)\n","\n","\n","\n","    def forward(self, src: Tensor, mask: Tensor) -> Tensor: ##传入mask\n","        emb=self.embedding(src)\n","        enc=self.encoder(emb,mask) ##传入mask\n","        out=self.out(enc)\n","        \n","        return out ##no need softmax, nn.cross_entropy take care of it"],"id":"11cf4eb7"},{"cell_type":"code","execution_count":32,"metadata":{"id":"11785966","executionInfo":{"status":"ok","timestamp":1665810896541,"user_tz":-480,"elapsed":153,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":[],"id":"11785966"},{"cell_type":"code","execution_count":32,"metadata":{"id":"e1a7b865","executionInfo":{"status":"ok","timestamp":1665810896548,"user_tz":-480,"elapsed":159,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":[],"id":"e1a7b865"},{"cell_type":"markdown","metadata":{"id":"02903460"},"source":["# load data"],"id":"02903460"},{"cell_type":"code","execution_count":32,"metadata":{"id":"919aebd4","executionInfo":{"status":"ok","timestamp":1665810896552,"user_tz":-480,"elapsed":159,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":[],"id":"919aebd4"},{"cell_type":"markdown","metadata":{"id":"9caecf34"},"source":["# train model"],"id":"9caecf34"},{"cell_type":"code","execution_count":33,"metadata":{"id":"bf2b36ea","executionInfo":{"status":"ok","timestamp":1665810896555,"user_tz":-480,"elapsed":160,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["# Generates a square matrix where the each row allows one word more to be seen\n","\n","def generate_masks(src):\n","    seq_len= src.size(1)\n","\n","    pad_int= [int(seq_len-i) for i in src.count_nonzero(dim=1)]\n","\n","    mask = torch.tril(torch.ones(seq_len, seq_len) == 1) # Lower triangular matrix\n","    mask = mask.float()\n","    mask = mask.masked_fill(mask == 0, -1e9) # Convert zeros to -1e9\n","    mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n","\n","    mask_arr=[]\n","    for i in pad_int:\n","      mask[:,-(i):]= -1e9\n","      mask_arr.append(mask)\n","\n","    masks=torch.cat(tuple(mask_arr),dim=0)\n","    masks=masks.reshape(src.size(0),seq_len,seq_len)\n","    \n","    return masks"],"id":"bf2b36ea"},{"cell_type":"code","execution_count":34,"metadata":{"id":"9f8d45f2","executionInfo":{"status":"ok","timestamp":1665810896559,"user_tz":-480,"elapsed":162,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[],"source":["import time\n","\n","######\n","def loss_masked(output, src, loss_fn):\n","    nonpad_int=src.count_nonzero(dim=1)\n","    # discard pad elements\n","    res=[]\n","    for k,item in enumerate(nonpad_int):\n","        res.append(src[k][:int(item)])\n","\n","    loss_res=0\n","    for i in range(src.size(0)):\n","        loss_res+=loss_fn(output[i], src[i])\n","\n","    return loss_res/src.size(0)\n","######\n","\n","def train_with_multigpu(model, data, batch_size):\n","    torch.manual_seed(0)\n","    # use data parallel to utilize multiple gpus\n","    model = nn.DataParallel(model)\n","    torch.cuda.set_device(device)\n","    model.cuda(device)\n","    ##\n","\n","    # define loss function (criterion) and optimizer\n","    loss_fn = nn.CrossEntropyLoss().to(device)  ## this is for classification\n","    opt = torch.optim.SGD(model.parameters(), 1e-4)\n","\n","\n","    n=len(data)// batch_size\n","\n","    # prepare for next word prediction\n","    t0=time.time()\n","\n","    for i in range(n):\n","        src=data[batch_size*i:batch_size*(i+1)]\n","        src=torch.tensor(src).long()\n","\n","        _seq=src[:,:-1]\n","        seq_=src[:,1:]\n","        masks=generate_masks(_seq)\n","\n","        \n","        #put to gpu, multiple gpu\n","        _seq=_seq.cuda(non_blocking=True) #\n","        seq_=seq_.cuda(non_blocking=True) #\n","        masks=masks.cuda(non_blocking=True) #\n","\n","        # Forward pass\n","        outputs = model(_seq,masks)\n","        loss=loss_masked(outputs,seq_, loss_fn) # next word prediction\n","\n","        # the part of padding loss should be removed before backprop\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n","        print(loss.detach().item())\n","    print(time.time()-t0)\n","        \n","        #if i%10000==0: np.savetxt('./torch_save_model/gpt_loss_%d.csv'%(i), np.array([loss.detach().item()]))\n","\n","    # save model parameters after finish training model\n","    torch.save(model, \"./model.pkl\")"],"id":"9f8d45f2"},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"JfdRCQmthltG","executionInfo":{"status":"ok","timestamp":1665810896564,"user_tz":-480,"elapsed":165,"user":{"displayName":"tim huang","userId":"03672479409652519123"}},"outputId":"046ff094-8aa9-46bb-8015-dd64515f773d"},"id":"JfdRCQmthltG","execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":36,"metadata":{"id":"90873858","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f341203-379d-4e26-e37f-3146e5b19ee3","executionInfo":{"status":"ok","timestamp":1665812823702,"user_tz":-480,"elapsed":1927290,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  \n"]},{"output_type":"stream","name":"stdout","text":["10.438931465148926\n","10.421241760253906\n","10.413071632385254\n","10.437469482421875\n","10.355743408203125\n","10.323569297790527\n","10.336320877075195\n","10.308444023132324\n","10.279337882995605\n","10.24304485321045\n","10.2999849319458\n","10.226543426513672\n","10.166796684265137\n","10.152738571166992\n","10.141679763793945\n","10.08499526977539\n","10.083168029785156\n","10.064270973205566\n","10.046416282653809\n","10.045695304870605\n","10.113969802856445\n","9.991279602050781\n","10.071061134338379\n","9.948297500610352\n","9.93919849395752\n","9.922298431396484\n","9.976054191589355\n","9.894980430603027\n","9.877127647399902\n","9.8079833984375\n","9.807838439941406\n","9.801541328430176\n","9.786789894104004\n","9.732682228088379\n","9.760115623474121\n","9.728918075561523\n","9.726072311401367\n","9.781535148620605\n","9.697854042053223\n","9.635692596435547\n","9.610631942749023\n","9.5361909866333\n","9.52513313293457\n","9.45449161529541\n","9.459996223449707\n","9.421398162841797\n","9.487081527709961\n","9.429513931274414\n","9.43146800994873\n","9.372628211975098\n","9.396965026855469\n","9.423199653625488\n","9.551289558410645\n","9.325583457946777\n","9.28954029083252\n","9.356084823608398\n","9.34683895111084\n","9.331504821777344\n","9.201793670654297\n","9.200934410095215\n","9.182686805725098\n","9.170549392700195\n","9.133353233337402\n","9.164742469787598\n","9.053132057189941\n","9.034074783325195\n","9.069836616516113\n","9.071246147155762\n","9.034639358520508\n","9.026987075805664\n","8.92130184173584\n","8.773368835449219\n","8.790989875793457\n","8.941901206970215\n","8.934178352355957\n","8.85904312133789\n","8.898214340209961\n","8.84664535522461\n","8.788158416748047\n","8.803716659545898\n","8.810808181762695\n","8.777539253234863\n","8.793087005615234\n","8.720232963562012\n","8.64206314086914\n","8.615161895751953\n","8.577253341674805\n","8.585286140441895\n","8.641715049743652\n","8.613670349121094\n","8.509218215942383\n","8.773955345153809\n","8.580113410949707\n","8.65617847442627\n","8.68449592590332\n","8.68549919128418\n","8.774733543395996\n","8.584704399108887\n","8.65853500366211\n","8.581128120422363\n","8.314644813537598\n","8.283063888549805\n","8.37122917175293\n","8.239995002746582\n","8.260040283203125\n","8.263741493225098\n","8.177138328552246\n","8.125165939331055\n","8.190377235412598\n","8.190108299255371\n","8.160751342773438\n","8.134920120239258\n","8.0791015625\n","8.118825912475586\n","8.106932640075684\n","8.068634986877441\n","8.188045501708984\n","8.14755916595459\n","7.981229782104492\n","8.139105796813965\n","8.05888843536377\n","8.063743591308594\n","7.95302152633667\n","7.9669718742370605\n","7.825313568115234\n","8.026041984558105\n","7.795713901519775\n","7.9166178703308105\n","7.800815582275391\n","7.697912216186523\n","7.800185203552246\n","7.721477508544922\n","7.731415748596191\n","7.809688568115234\n","7.653162002563477\n","7.626344203948975\n","7.670967102050781\n","7.701842784881592\n","7.875774383544922\n","7.537885665893555\n","7.43449068069458\n","7.571268081665039\n","7.5328779220581055\n","7.393552780151367\n","7.440550804138184\n","7.460382461547852\n","7.57240629196167\n","7.488548755645752\n","7.3519110679626465\n","7.274447441101074\n","7.355716705322266\n","7.385926246643066\n","7.444076061248779\n","7.529306411743164\n","7.406957626342773\n","7.534962177276611\n","7.337053298950195\n","7.377444267272949\n","7.175426006317139\n","7.197371959686279\n","7.321406364440918\n","7.247883319854736\n","7.194385528564453\n","7.206131935119629\n","7.247889041900635\n","6.810157775878906\n","7.2401442527771\n","7.116534233093262\n","7.00126838684082\n","6.866755485534668\n","7.155642032623291\n","7.0827484130859375\n","6.951552391052246\n","7.09857177734375\n","7.260625839233398\n","6.971308708190918\n","7.0515546798706055\n","7.27957820892334\n","6.865938663482666\n","6.708158016204834\n","6.783717632293701\n","6.800398349761963\n","6.962128639221191\n","7.101383686065674\n","6.601769924163818\n","6.603592395782471\n","6.93146276473999\n","6.72998046875\n","6.748272895812988\n","6.9098687171936035\n","6.731462001800537\n","6.558595657348633\n","6.572736740112305\n","6.63041877746582\n","6.87809419631958\n","6.735378742218018\n","6.743040561676025\n","6.5325541496276855\n","6.603402614593506\n","6.470759391784668\n","6.496302604675293\n","6.1504411697387695\n","6.548689842224121\n","6.206871032714844\n","6.5679545402526855\n","6.368027210235596\n","6.908783435821533\n","6.518252849578857\n","6.359718322753906\n","6.126530170440674\n","6.296494483947754\n","6.30999231338501\n","6.312755107879639\n","6.465643405914307\n","6.50179386138916\n","6.35935115814209\n","6.214718341827393\n","6.267458438873291\n","5.991494655609131\n","6.249668121337891\n","6.341748237609863\n","6.149694919586182\n","5.987228870391846\n","6.028477668762207\n","5.912335395812988\n","5.899209976196289\n","5.847433090209961\n","6.041306495666504\n","5.9941864013671875\n","6.086368083953857\n","5.916106700897217\n","5.890398979187012\n","6.4438934326171875\n","6.1940598487854\n","6.142556667327881\n","6.033228397369385\n","5.755963325500488\n","5.785107135772705\n","5.898462772369385\n","6.068790435791016\n","5.824792861938477\n","6.006256580352783\n","6.231154918670654\n","5.856632709503174\n","5.958247184753418\n","6.335299015045166\n","5.865200519561768\n","5.6160430908203125\n","5.406304359436035\n","5.708950996398926\n","5.577702045440674\n","5.902770042419434\n","5.508692741394043\n","5.4012370109558105\n","5.57485818862915\n","5.480127811431885\n","5.846341609954834\n","5.6751389503479\n","5.774379730224609\n","5.876833915710449\n","5.332690238952637\n","5.464745044708252\n","5.269332408905029\n","5.497533321380615\n","5.380459785461426\n","5.24270486831665\n","5.569859981536865\n","5.446314811706543\n","5.224632740020752\n","5.121049404144287\n","5.429379940032959\n","5.311699867248535\n","5.737362384796143\n","5.458754539489746\n","5.784714698791504\n","5.050831317901611\n","5.0011491775512695\n","4.862456321716309\n","4.787954807281494\n","4.887438774108887\n","5.2132134437561035\n","5.209956645965576\n","4.986519813537598\n","5.202703475952148\n","5.195852279663086\n","4.811397075653076\n","4.991349697113037\n","5.163621425628662\n","5.529147624969482\n","5.086065769195557\n","5.0962443351745605\n","4.768866062164307\n","4.769476413726807\n","4.722832679748535\n","4.733820915222168\n","5.163112163543701\n","4.903116226196289\n","4.704243183135986\n","4.803104400634766\n","4.899243354797363\n","4.951085090637207\n","5.030369281768799\n","4.980198383331299\n","4.784383773803711\n","4.408420085906982\n","4.6391682624816895\n","4.803472518920898\n","4.953553199768066\n","5.0474419593811035\n","4.780585289001465\n","4.435698509216309\n","4.497655868530273\n","5.097739219665527\n","5.443583011627197\n","5.050280570983887\n","4.955564975738525\n","4.869429111480713\n","4.575496196746826\n","4.911649227142334\n","4.424276351928711\n","4.564281463623047\n","4.6324687004089355\n","5.057643413543701\n","4.53854513168335\n","4.523624897003174\n","4.928481578826904\n","4.374390602111816\n","3.551677703857422\n","3.526521682739258\n","4.596837043762207\n","4.063023090362549\n","5.0290985107421875\n","4.759152889251709\n","4.832771301269531\n","4.667471408843994\n","4.868346214294434\n","4.417478561401367\n","4.243254661560059\n","4.2801289558410645\n","4.04337739944458\n","3.941873073577881\n","4.298811435699463\n","4.091432094573975\n","4.207576274871826\n","3.8523783683776855\n","3.8232572078704834\n","4.033917427062988\n","4.5012688636779785\n","4.065057754516602\n","4.109563827514648\n","4.250611305236816\n","4.182367324829102\n","4.273159503936768\n","4.4524149894714355\n","5.186192989349365\n","4.922920227050781\n","5.382896900177002\n","4.815201282501221\n","4.4334259033203125\n","4.800994396209717\n","4.557321548461914\n","4.146607398986816\n","4.1545305252075195\n","4.091886043548584\n","4.263242244720459\n","4.348641395568848\n","4.234742164611816\n","3.9237518310546875\n","4.311757564544678\n","4.137241840362549\n","4.124997138977051\n","3.9768030643463135\n","4.533293724060059\n","3.919205904006958\n","3.910036325454712\n","5.043956756591797\n","4.8431077003479\n","4.706855773925781\n","4.386160850524902\n","4.450534820556641\n","4.298893451690674\n","4.419172763824463\n","4.580770015716553\n","4.024828910827637\n","3.721000909805298\n","4.050012111663818\n","4.4264655113220215\n","4.244511127471924\n","4.2023797035217285\n","3.791606903076172\n","4.173344612121582\n","3.8973817825317383\n","3.7644877433776855\n","3.7178406715393066\n","3.342944383621216\n","3.8264002799987793\n","3.6996796131134033\n","4.721778869628906\n","5.07453727722168\n","4.035035610198975\n","3.9814677238464355\n","3.9845151901245117\n","3.9193453788757324\n","3.9299817085266113\n","3.7352683544158936\n","3.7486095428466797\n","3.8619608879089355\n","3.9655678272247314\n","5.180006980895996\n","4.559892654418945\n","3.974966526031494\n","4.15297269821167\n","4.192760944366455\n","3.9511749744415283\n","3.7748281955718994\n","3.378507137298584\n","3.056157350540161\n","3.6991775035858154\n","4.10209321975708\n","4.021907329559326\n","3.9079854488372803\n","4.12892484664917\n","3.9077627658843994\n","3.143409252166748\n","3.216549873352051\n","4.1121826171875\n","4.266467094421387\n","4.295295715332031\n","3.6664834022521973\n","3.7073445320129395\n","3.9094011783599854\n","4.002188205718994\n","3.929474115371704\n","3.784985065460205\n","4.11397123336792\n","4.3889851570129395\n","3.8225760459899902\n","3.153137683868408\n","3.6173150539398193\n","4.363044261932373\n","3.489429235458374\n","3.353097438812256\n","3.082753896713257\n","3.3700449466705322\n","3.925438404083252\n","4.026363372802734\n","3.86806321144104\n","3.0354292392730713\n","2.762458324432373\n","3.6569390296936035\n","3.7221264839172363\n","3.5891473293304443\n","3.3081419467926025\n","3.446493625640869\n","3.5668177604675293\n","2.991494655609131\n","3.504077196121216\n","3.54190993309021\n","3.6705617904663086\n","4.021358966827393\n","4.219901084899902\n","4.408775329589844\n","4.209226131439209\n","3.5801353454589844\n","3.5819756984710693\n","3.7274489402770996\n","3.3183507919311523\n","3.2191827297210693\n","3.67928147315979\n","3.829545021057129\n","3.6517562866210938\n","3.517526388168335\n","3.350647211074829\n","3.131056785583496\n","3.84660267829895\n","3.7477519512176514\n","3.818643569946289\n","3.3957536220550537\n","3.7867274284362793\n","3.7054388523101807\n","3.356757164001465\n","3.5005736351013184\n","3.4660398960113525\n","2.9609408378601074\n","3.1231155395507812\n","3.4595694541931152\n","3.6269466876983643\n","3.5682175159454346\n","3.7642810344696045\n","3.649303913116455\n","3.615300416946411\n","3.374168872833252\n","3.76232647895813\n","3.5413103103637695\n","3.0510778427124023\n","3.5691113471984863\n","3.173969030380249\n","3.4102694988250732\n","3.9726321697235107\n","3.519442081451416\n","3.749119281768799\n","3.1353046894073486\n","4.1233930587768555\n","3.8847293853759766\n","3.4457077980041504\n","3.8749217987060547\n","3.371415376663208\n","3.313427448272705\n","3.119042158126831\n","3.4139201641082764\n","3.5052685737609863\n","3.210753917694092\n","2.980640172958374\n","2.615772008895874\n","2.940459966659546\n","3.5755746364593506\n","3.3898561000823975\n","3.2411928176879883\n","3.306687593460083\n","3.78878116607666\n","3.8332433700561523\n","3.3527865409851074\n","3.7368345260620117\n","3.4350571632385254\n","3.1911401748657227\n","3.3342628479003906\n","2.937091827392578\n","3.604076623916626\n","3.4697420597076416\n","3.1369900703430176\n","3.1871907711029053\n","3.7858104705810547\n","3.814387798309326\n","3.591125011444092\n","3.1991021633148193\n","3.3509304523468018\n","3.627584934234619\n","2.753058433532715\n","3.3701419830322266\n","3.8898234367370605\n","3.6269524097442627\n","3.5387632846832275\n","3.354012966156006\n","3.5420055389404297\n","3.844052791595459\n","3.3889987468719482\n","3.7816953659057617\n","3.6229021549224854\n","2.889418601989746\n","3.0450782775878906\n","3.092264413833618\n","2.900428295135498\n","3.5534138679504395\n","3.6468191146850586\n","3.704704999923706\n","3.841820001602173\n","3.755626678466797\n","3.932555913925171\n","3.4369068145751953\n","4.280189037322998\n","3.86397123336792\n","3.491220474243164\n","3.74019193649292\n","3.81687593460083\n","3.247100591659546\n","3.3961782455444336\n","3.5808849334716797\n","3.45277738571167\n","3.251220703125\n","3.574465036392212\n","3.363746166229248\n","2.619565725326538\n","3.652247190475464\n","3.4865493774414062\n","3.322340250015259\n","2.732044219970703\n","2.6471776962280273\n","2.9942471981048584\n","2.8438611030578613\n","2.8961827754974365\n","2.6410984992980957\n","2.975433588027954\n","2.827343702316284\n","3.1311721801757812\n","3.222101926803589\n","3.348426103591919\n","1873.686428308487\n"]}],"source":["# the entry to start training the model, with data, with specified parameter\n","if __name__ == '__main__':\n","    # load cpu or gpu name\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","    # model parameter\n","    MODEL_DIM = 256\n","    N_LAYER = 4\n","    N_HEAD = 8\n","    # training argument\n","    batch_size = 128\n","    # load data\n","    ut = utils(path='/content/drive/MyDrive/goodnlp-github-data/single_gpu_pytorch_gpt/file00')\n","    d, v2i=ut.get_idx_sentence()\n","    n_vocab= len(v2i)\n","    m= GPT(num_encoder_layers= N_LAYER,dim_model= MODEL_DIM, num_heads= N_HEAD, n_vocab=n_vocab, device=device)\n","    # start training\n","    train_with_multigpu(m, d, batch_size)"],"id":"90873858"},{"cell_type":"code","source":[],"metadata":{"id":"VekROXT-0Ksk","executionInfo":{"status":"ok","timestamp":1665812823706,"user_tz":-480,"elapsed":74,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"id":"VekROXT-0Ksk","execution_count":36,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q7hvTYl-0K45","executionInfo":{"status":"ok","timestamp":1665812823708,"user_tz":-480,"elapsed":65,"user":{"displayName":"tim huang","userId":"03672479409652519123"}}},"id":"Q7hvTYl-0K45","execution_count":36,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1o7hz4unyEbrEa215fqKweoYtGaWedgSk","timestamp":1665765566278}],"collapsed_sections":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}